---
title: "Online Shoppers Intention classification using Boosting"
author: "Nicola Disabato"
date: "2022-08-01"
output:
  github_document:
    html_preview: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Importing libraries

```{r}
library(magrittr) 
library(dplyr)
library(caret)
library(fastAdaboost)
library(Matrix)
library(ROCR)
library(pROC)
library(xgboost)
library(gbm)
```

## Importing the dataset

```{r}
# Load the dataset and explore
intentions <- read.csv("online_shoppers_intention.csv", header = TRUE) 
str(intentions)
```

```{r}
table(intentions$Revenue)
```

As you can see, the dataset is made up of 12330 instances and 18 features. Of these observations, only 1908 are users who have finalized a purchase.

All details can be found through the following link: <https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset#>

## Data Preparation

```{r}
intentions <- intentions %>% 
  mutate(OperatingSystems = as.factor(OperatingSystems),
         Browser = as.factor(Browser),
         Region = as.factor(Region),
         TrafficType = as.factor(TrafficType),
         VisitorType = as.factor(VisitorType),
         Month = as.factor(Month)
         )

intentions <- intentions %>% 
  mutate(
         Weekend = as.numeric(Weekend),
         Revenue = as.numeric(Revenue)
         )

str(intentions)
```

We use one-hot encoding for categorical variables.

```{r}
dmy <- dummyVars(" ~ .", data = intentions)
intentions <- data.frame(predict(dmy, newdata = intentions))

dim(intentions)

```

After the preprocessing phase, we obtain a dataset with 75 features.

## Train and Test partition

```{r}
set.seed(100)
inTrain <- createDataPartition(y = intentions$Revenue, p = .75, list = FALSE)
train <- intentions[ inTrain,] 
test <- intentions[-inTrain,]

X_train <- sparse.model.matrix(Revenue ~ .-1, data = train)
y_train <- train[,"Revenue"]  
X_test <- sparse.model.matrix(Revenue~.-1, data = test)
y_test <- test[,"Revenue"]
```

## Let's explore AdaBoost model

```{r}
model_adaboost <- adaboost(Revenue ~ ., data=train, nIter=10)
model_adaboost
```

After training the model on the train dataset, you can use the predict () method to predict the output of the Revenue class in the test dataset. To analyze the performance of the model, it was decided to print the confusion matrix in addition to the precision, recall and f1-score metrics, in addition to the accuracy metric.

```{r}
#predictions
pred_ada = predict(model_adaboost, newdata=test)

#confusion matrix creation
cm = confusionMatrix(as.factor(pred_ada$class),as.factor(y_test), positive = '1')
cm
print(cm$byClass[5])
print(cm$byClass[6])
print(cm$byClass[7])
```

It is immediately evident how the classification model, despite having an accuracy value of 0.88, is found to be not very precise as the values of Precision, Recall and F1 are quite low. This often happens in these cases, that is with the presence of unbalanced classes: in such cases the accuracy metric is not very informative.

To build the best possible Adaboost model, depending on the dataset, we have chosen to build a graph from which to display the best number of decision trees (of iterations) to specify to build a more precise model, based on the errors made.

```{r}
best_adaboost <- adaboost(Revenue ~ ., data=train, nIter=125)

#predictions
pred_best_ada = predict(best_adaboost, newdata=test)

#confusion matrix creation
cm <- confusionMatrix(as.factor(pred_best_ada$class),as.factor(y_test), positive = '1')
cm
print(cm$byClass[5])
print(cm$byClass[6])
print(cm$byClass[7])
```

From the results it is possible to observe how better results have been achieved, starting from the Precision metric which describes a greater precision in the prediction of the positive label 1 which passes from 0.68 to 0.75. The other metrics remain similar.
